{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Severity prediction of bug reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Preprocess: \n",
    "- Embedding using:\n",
    "- Algorithms for binary classification:\n",
    "- Metrics: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "import re\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "from sklearn.naive_bayes import BernoulliNB, GaussianNB, ComplementNB, MultinomialNB\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from baseline_functions import filter_bug_severity, create_binary_feature, remove_urls_and_codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 361006 entries, 0 to 361005\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   _id           361006 non-null  object\n",
      " 1   bug_id        361006 non-null  int64 \n",
      " 2   product       361006 non-null  object\n",
      " 3   description   361006 non-null  object\n",
      " 4   bug_severity  361006 non-null  object\n",
      " 5   dup_id        361006 non-null  object\n",
      " 6   short_desc    361006 non-null  object\n",
      " 7   priority      361006 non-null  object\n",
      " 8   version       361006 non-null  object\n",
      " 9   component     361006 non-null  object\n",
      " 10  delta_ts      361006 non-null  object\n",
      " 11  bug_status    361006 non-null  object\n",
      " 12  creation_ts   361006 non-null  object\n",
      " 13  resolution    361006 non-null  object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 38.6+ MB\n"
     ]
    }
   ],
   "source": [
    "bug_reports_ = pd.read_json('data/eclipse_clear.json', lines=True)\n",
    "bug_reports_.info()\n",
    "############ fazer um script para pegar o summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60000 entries, 0 to 59999\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   _id           60000 non-null  object\n",
      " 1   bug_id        60000 non-null  int64 \n",
      " 2   product       60000 non-null  object\n",
      " 3   description   60000 non-null  object\n",
      " 4   bug_severity  60000 non-null  object\n",
      " 5   dup_id        60000 non-null  object\n",
      " 6   short_desc    60000 non-null  object\n",
      " 7   priority      60000 non-null  object\n",
      " 8   version       60000 non-null  object\n",
      " 9   component     60000 non-null  object\n",
      " 10  delta_ts      60000 non-null  object\n",
      " 11  bug_status    60000 non-null  object\n",
      " 12  creation_ts   60000 non-null  object\n",
      " 13  resolution    60000 non-null  object\n",
      "dtypes: int64(1), object(13)\n",
      "memory usage: 6.4+ MB\n"
     ]
    }
   ],
   "source": [
    "bug_reports = bug_reports_[:60000]\n",
    "bug_reports.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['normal', 'major', 'enhancement', 'critical', 'minor', 'trivial',\n",
       "       'blocker'], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bug_reports.bug_severity.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>bug_id</th>\n",
       "      <th>description</th>\n",
       "      <th>bug_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'$oid': '52e9b44954dc1c25ebdb1f11'}</td>\n",
       "      <td>43</td>\n",
       "      <td>I have a project (Junk) that has been released...</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>{'$oid': '52e9b44f54dc1c25ebdb1f87'}</td>\n",
       "      <td>163</td>\n",
       "      <td>AK (6/12/01 4:55:24 PM)\\n\\ti got this exceptio...</td>\n",
       "      <td>critical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>{'$oid': '52e9b45054dc1c25ebdb1fa5'}</td>\n",
       "      <td>194</td>\n",
       "      <td>1) Add a global ignore pattern \"BazProject\"\\n2...</td>\n",
       "      <td>major</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      _id  bug_id  \\\n",
       "44   {'$oid': '52e9b44954dc1c25ebdb1f11'}      43   \n",
       "162  {'$oid': '52e9b44f54dc1c25ebdb1f87'}     163   \n",
       "192  {'$oid': '52e9b45054dc1c25ebdb1fa5'}     194   \n",
       "\n",
       "                                           description bug_severity  \n",
       "44   I have a project (Junk) that has been released...        major  \n",
       "162  AK (6/12/01 4:55:24 PM)\\n\\ti got this exceptio...     critical  \n",
       "192  1) Add a global ignore pattern \"BazProject\"\\n2...        major  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_df = filter_bug_severity(bug_reports, col='bug_severity')\n",
    "filter_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>bug_id</th>\n",
       "      <th>description</th>\n",
       "      <th>bug_severity</th>\n",
       "      <th>binary_severity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>{'$oid': '52e9b44954dc1c25ebdb1f11'}</td>\n",
       "      <td>43</td>\n",
       "      <td>I have a project (Junk) that has been released...</td>\n",
       "      <td>major</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>{'$oid': '52e9b44f54dc1c25ebdb1f87'}</td>\n",
       "      <td>163</td>\n",
       "      <td>AK (6/12/01 4:55:24 PM)\\n\\ti got this exceptio...</td>\n",
       "      <td>critical</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>{'$oid': '52e9b45054dc1c25ebdb1fa5'}</td>\n",
       "      <td>194</td>\n",
       "      <td>1) Add a global ignore pattern \"BazProject\"\\n2...</td>\n",
       "      <td>major</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      _id  bug_id  \\\n",
       "44   {'$oid': '52e9b44954dc1c25ebdb1f11'}      43   \n",
       "162  {'$oid': '52e9b44f54dc1c25ebdb1f87'}     163   \n",
       "192  {'$oid': '52e9b45054dc1c25ebdb1fa5'}     194   \n",
       "\n",
       "                                           description bug_severity  \\\n",
       "44   I have a project (Junk) that has been released...        major   \n",
       "162  AK (6/12/01 4:55:24 PM)\\n\\ti got this exceptio...     critical   \n",
       "192  1) Add a global ignore pattern \"BazProject\"\\n2...        major   \n",
       "\n",
       "     binary_severity  \n",
       "44                 1  \n",
       "162                1  \n",
       "192                1  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df = create_binary_feature(filter_df, col='bug_severity')\n",
    "binary_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "# check as remover without flag, and as it is in the data\n",
    "def remove_code_snippets(text):\n",
    "    # Remove programming code snippets enclosed in triple backticks\n",
    "    code_pattern = r'```(?:[^`]+|`(?!``))*```'\n",
    "    text_without_code = re.sub(code_pattern, 'CODE', text)\n",
    "\n",
    "    # Remove programming code snippets enclosed in single backticks\n",
    "    text_without_code = re.sub(r'`[^`]+`', '', text_without_code)\n",
    "\n",
    "    return text_without_code\n",
    "\n",
    "def remove_urls_and_codes(dataframe, col='description'):\n",
    "    test = dataframe[col].apply(lambda text: print(type(text)))\n",
    "    dataframe[col] = dataframe[col].apply(lambda text: re.sub(r'http\\S+', '', text))\n",
    "    dataframe[col] = dataframe[col].apply(lambda text: remove_code_snippets(text))\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_df = remove_urls_and_codes(binary_df, col='description')\n",
    "url_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adicionar o tratamento do campo vazio ??\n",
    "remove_urls_and_codes(bug_reports, col='description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(dataframe, col='description'):\n",
    "    bug_reports_copy = dataframe.copy()\n",
    "    \n",
    "    tokens = bug_reports_copy[col].apply(word_tokenize)\n",
    "    \n",
    "    # Get the set of stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Define the special characters to remove\n",
    "    # in the article doesn't include this step\n",
    "    special_characters = set(string.punctuation)\n",
    "    special_characters.add('``')\n",
    "    special_characters.add(\"''\")\n",
    "    # there is also:  \"n't\" / checkar\n",
    "    \n",
    "    # Initialize the stemmer\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    # Apply stop-word removal and stemming\n",
    "    filtered_texts = []\n",
    "    for tokens in tokens:\n",
    "        filtered_tokens = [stemmer.stem(token) for token in tokens if token.lower() not in stop_words and token not in special_characters]\n",
    "        # filtered_texts.append(filtered_tokens)\n",
    "        filtered_texts.append(' '.join(filtered_tokens))\n",
    "    #print('\\nfiltered_texts', filtered_texts)\n",
    "    bug_reports_copy['preprocess_desc'] = filtered_texts\n",
    "    \n",
    "    return bug_reports_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checar se estou tratando os enters\n",
    "# qual a melhor ordem de colocar o tratamento dos enters\n",
    "# testar o passo de remover URL e CODE\n",
    "# checar a estrutura da primeira referencia\n",
    "# fazer os testes em pedaços dos bugs e ir salvando os arquivos (chuncks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = preprocess_text(bug_reports, col='description')\n",
    "test.to_csv('my_dataframe.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('bug_severity_filter', FunctionTransformer(filter_bug_severity, kw_args={'col': 'bug_severity'})),\n",
    "    ('binary_feature', FunctionTransformer(create_binary_feature, kw_args={'col': 'bug_severity'})),\n",
    "    ('remove_url_and_code', FunctionTransformer(remove_urls_and_codes, kw_args={'col': 'description'})),\n",
    "    ('preprocessor', FunctionTransformer(preprocess_text, kw_args={'col': 'description'})),\n",
    "    # ('embedding', embedding),\n",
    "    # ('classifier', classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.fit(bug_reports)\n",
    "\n",
    "# Get the transformed data at the filter_bug_severity step\n",
    "filter_bug_severity_result = pipeline.named_steps['bug_severity_filter'].transform(bug_reports) # ver sobre a seleção das colunas\n",
    "print('First step')\n",
    "print('Columns:', filter_bug_severity_result.columns)\n",
    "print('Return type:', type(filter_bug_severity_result))\n",
    "print(\"Severities's kind:\", filter_bug_severity_result.bug_severity.unique(), '\\n')\n",
    "\n",
    "# Get the transformed data at the binary_feature step\n",
    "binary_feature_result = pipeline.named_steps['binary_feature'].transform(filter_bug_severity_result)\n",
    "print('Second step')\n",
    "print('Columns:', binary_feature_result.columns)\n",
    "print('Return type:', type(binary_feature_result))\n",
    "print(\"Severities's kind:\", binary_feature_result.binary_severity.unique(), '\\n')\n",
    "\n",
    "# Get the transformed data at the preprocessor\n",
    "preprocessor_result = pipeline.named_steps['preprocessor'].transform(binary_feature_result)\n",
    "#print('Third step')\n",
    "#print('Columns:', preprocessor_result.columns)\n",
    "#print('Return type:', type(preprocessor_result))\n",
    "#print(\"Severities's kind:\", preprocessor_result.head(3).preprocess_desc, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipeline Naive Bayes\n",
    "\n",
    "Article of A. Lamkanfi (Comparing...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Binary representation (CountVectorizer)\n",
    "binary_representation = CountVectorizer()\n",
    "\n",
    "# Define the Naive Bayes classifier\n",
    "naive_bayes_classifier = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocess_pipeline = Pipeline([\n",
    "    ('bug_severity_filter', FunctionTransformer(filter_bug_severity, kw_args={'col': 'bug_severity'})),\n",
    "    ('binary_feature', FunctionTransformer(create_binary_feature, kw_args={'col': 'bug_severity'})),\n",
    "    ('preprocessor', FunctionTransformer(preprocess_text, kw_args={'col': 'description'})),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_preprocessed = data_preprocess_pipeline.transform(bug_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 11232 entries, 44 to 59999\n",
      "Data columns (total 6 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   _id              11232 non-null  object\n",
      " 1   bug_id           11232 non-null  int64 \n",
      " 2   description      11232 non-null  object\n",
      " 3   bug_severity     11232 non-null  object\n",
      " 4   binary_severity  11232 non-null  int64 \n",
      " 5   preprocess_desc  11232 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 614.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data_preprocessed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63651 ['00' '000' '0000' ... 'あいうえお' '九月' '論理ﾋﾞｭｰ']\n",
      "11232 \n",
      " [[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create bag-of-words representation\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(data_preprocessed['preprocess_desc'])\n",
    "# print('bag_of_words', bag_of_words)\n",
    "\n",
    "# Get the feature names\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(len(feature_names), feature_names)\n",
    "\n",
    "# Print the bag-of-words representation\n",
    "print(len(bag_of_words.toarray()), '\\n', bag_of_words.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = bag_of_words.toarray()\n",
    "y = data_preprocessed['binary_severity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold cross-validation\n",
    "k = 10\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Accuracy: 0.5598, Test Accuracy: 0.5142\n",
      "Fold 2 - Train Accuracy: 0.5540, Test Accuracy: 0.5311\n",
      "Fold 3 - Train Accuracy: 0.5579, Test Accuracy: 0.5236\n",
      "Fold 4 - Train Accuracy: 0.5560, Test Accuracy: 0.5076\n",
      "Fold 5 - Train Accuracy: 0.5568, Test Accuracy: 0.5467\n",
      "Fold 6 - Train Accuracy: 0.5612, Test Accuracy: 0.5200\n",
      "Fold 7 - Train Accuracy: 0.5560, Test Accuracy: 0.4871\n",
      "Fold 8 - Train Accuracy: 0.5572, Test Accuracy: 0.5503\n",
      "Fold 9 - Train Accuracy: 0.5521, Test Accuracy: 0.5165\n",
      "Fold 10 - Train Accuracy: 0.5611, Test Accuracy: 0.5316\n",
      "Mean Train Accuracy: 0.5572, Mean Test Accuracy: 0.5229\n"
     ]
    }
   ],
   "source": [
    "############# Bernouli\n",
    "\n",
    "# Initialize lists to store train and test accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate through each fold\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    naive_bayes_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = naive_bayes_classifier.predict(X_test)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    y_train_pred = naive_bayes_classifier.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Print accuracies for this fold\n",
    "    print(f'Fold {fold + 1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Calculate and print mean accuracies across all folds\n",
    "mean_train_accuracy = sum(train_accuracies) / k\n",
    "mean_test_accuracy = sum(test_accuracies) / k\n",
    "print(f'Mean Train Accuracy: {mean_train_accuracy:.4f}, Mean Test Accuracy: {mean_test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Accuracy: 0.8635, Test Accuracy: 0.6637\n",
      "Fold 2 - Train Accuracy: 0.8624, Test Accuracy: 0.6619\n",
      "Fold 3 - Train Accuracy: 0.8614, Test Accuracy: 0.6759\n",
      "Fold 4 - Train Accuracy: 0.8639, Test Accuracy: 0.6429\n",
      "Fold 5 - Train Accuracy: 0.8633, Test Accuracy: 0.6687\n",
      "Fold 6 - Train Accuracy: 0.8616, Test Accuracy: 0.6723\n",
      "Fold 7 - Train Accuracy: 0.8645, Test Accuracy: 0.6447\n",
      "Fold 8 - Train Accuracy: 0.8624, Test Accuracy: 0.6741\n",
      "Fold 9 - Train Accuracy: 0.8615, Test Accuracy: 0.6723\n",
      "Fold 10 - Train Accuracy: 0.8641, Test Accuracy: 0.6759\n",
      "Mean Train Accuracy: 0.8629, Mean Test Accuracy: 0.6652\n"
     ]
    }
   ],
   "source": [
    "############# GaussianNB\n",
    "\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "\n",
    "# Initialize lists to store train and test accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate through each fold\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    naive_bayes_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = naive_bayes_classifier.predict(X_test)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    y_train_pred = naive_bayes_classifier.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Print accuracies for this fold\n",
    "    print(f'Fold {fold + 1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Calculate and print mean accuracies across all folds\n",
    "mean_train_accuracy = sum(train_accuracies) / k\n",
    "mean_test_accuracy = sum(test_accuracies) / k\n",
    "print(f'Mean Train Accuracy: {mean_train_accuracy:.4f}, Mean Test Accuracy: {mean_test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - ROC AUC: 0.6267\n",
      "Fold 1 - Train Accuracy: 0.8635, Test Accuracy: 0.6637\n",
      "Fold 2 - ROC AUC: 0.6445\n",
      "Fold 2 - Train Accuracy: 0.8624, Test Accuracy: 0.6619\n",
      "Fold 3 - ROC AUC: 0.6506\n",
      "Fold 3 - Train Accuracy: 0.8614, Test Accuracy: 0.6759\n",
      "Fold 4 - ROC AUC: 0.6226\n",
      "Fold 4 - Train Accuracy: 0.8639, Test Accuracy: 0.6429\n",
      "Fold 5 - ROC AUC: 0.6345\n",
      "Fold 5 - Train Accuracy: 0.8633, Test Accuracy: 0.6687\n",
      "Fold 6 - ROC AUC: 0.6375\n",
      "Fold 6 - Train Accuracy: 0.8616, Test Accuracy: 0.6723\n",
      "Fold 7 - ROC AUC: 0.6117\n",
      "Fold 7 - Train Accuracy: 0.8645, Test Accuracy: 0.6447\n",
      "Fold 8 - ROC AUC: 0.6450\n",
      "Fold 8 - Train Accuracy: 0.8624, Test Accuracy: 0.6741\n",
      "Fold 9 - ROC AUC: 0.6311\n",
      "Fold 9 - Train Accuracy: 0.8615, Test Accuracy: 0.6723\n",
      "Fold 10 - ROC AUC: 0.6563\n",
      "Fold 10 - Train Accuracy: 0.8641, Test Accuracy: 0.6759\n",
      "Mean Train Accuracy: 0.8629, Mean Test Accuracy: 0.6652\n"
     ]
    }
   ],
   "source": [
    "############# GaussianNB\n",
    "\n",
    "naive_bayes_classifier = GaussianNB()\n",
    "\n",
    "# Initialize lists to store train and test accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate through each fold\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    naive_bayes_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = naive_bayes_classifier.predict(X_test)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    y_train_pred = naive_bayes_classifier.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f'Fold {fold + 1} - ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "    # Print accuracies for this fold\n",
    "    print(f'Fold {fold + 1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Calculate and print mean accuracies across all folds\n",
    "mean_train_accuracy = sum(train_accuracies) / k\n",
    "mean_test_accuracy = sum(test_accuracies) / k\n",
    "print(f'Mean Train Accuracy: {mean_train_accuracy:.4f}, Mean Test Accuracy: {mean_test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean AUC: 0.63605"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Train Accuracy: 0.4556, Test Accuracy: 0.4297\n",
      "Fold 2 - Train Accuracy: 0.4502, Test Accuracy: 0.4422\n",
      "Fold 3 - Train Accuracy: 0.4503, Test Accuracy: 0.4461\n",
      "Fold 4 - Train Accuracy: 0.4500, Test Accuracy: 0.4354\n",
      "Fold 5 - Train Accuracy: 0.4532, Test Accuracy: 0.4337\n",
      "Fold 6 - Train Accuracy: 0.4552, Test Accuracy: 0.4408\n",
      "Fold 7 - Train Accuracy: 0.4528, Test Accuracy: 0.4159\n",
      "Fold 8 - Train Accuracy: 0.4502, Test Accuracy: 0.4550\n",
      "Fold 9 - Train Accuracy: 0.4540, Test Accuracy: 0.4203\n",
      "Fold 10 - Train Accuracy: 0.4528, Test Accuracy: 0.4497\n",
      "Mean Train Accuracy: 0.4524, Mean Test Accuracy: 0.4369\n"
     ]
    }
   ],
   "source": [
    "############# ComplementNB\n",
    "\n",
    "naive_bayes_classifier = ComplementNB()\n",
    "\n",
    "# Initialize lists to store train and test accuracies\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Iterate through each fold\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    naive_bayes_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = naive_bayes_classifier.predict(X_test)\n",
    "\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    y_train_pred = naive_bayes_classifier.predict(X_train)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Print accuracies for this fold\n",
    "    print(f'Fold {fold + 1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "# Calculate and print mean accuracies across all folds\n",
    "mean_train_accuracy = sum(train_accuracies) / k\n",
    "mean_test_accuracy = sum(test_accuracies) / k\n",
    "print(f'Mean Train Accuracy: {mean_train_accuracy:.4f}, Mean Test Accuracy: {mean_test_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bag_of_words(texts):\n",
    "    vectorizer = CountVectorizer()\n",
    "    bag_of_words = vectorizer.fit_transform(data_preprocessed['preprocess_desc'])\n",
    "\n",
    "    return bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_pipeline = Pipeline([\n",
    "    ('embedding', FunctionTransformer(bag_of_words)),\n",
    "    ('classifier', naive_bayes_classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2861\n",
      "2861\n",
      "2861\n",
      "2861\n",
      "2861\n",
      "2861\n",
      "2861\n",
      "2861\n",
      "2861\n",
      "2862\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 240, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 312, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"C:\\Users\\dessa\\AppData\\Local\\Temp\\ipykernel_364\\580279345.py\", line 4, in bag_of_words\n    bag_of_words = binary_representation.fit_transform(texts.tolist)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1383, in fit_transform\n    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1268, in _count_vocab\n    for doc in raw_documents:\nTypeError: 'method' object is not iterable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[132], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m skf \u001b[39m=\u001b[39m StratifiedKFold(n_splits\u001b[39m=\u001b[39mk, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m      5\u001b[0m \u001b[39m# Calculate accuracy using cross_val_score\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m accuracy_scores \u001b[39m=\u001b[39m cross_val_score(complete_pipeline, X, y, cv\u001b[39m=\u001b[39;49mskf, scoring\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39maccuracy\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Calculate and print mean accuracy across all folds\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[39m#mean_accuracy = accuracy_scores.mean()\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m#print(f'Mean Accuracy: {mean_accuracy:.4f}')\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:562\u001b[0m, in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[39m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[0;32m    560\u001b[0m scorer \u001b[39m=\u001b[39m check_scoring(estimator, scoring\u001b[39m=\u001b[39mscoring)\n\u001b[1;32m--> 562\u001b[0m cv_results \u001b[39m=\u001b[39m cross_validate(\n\u001b[0;32m    563\u001b[0m     estimator\u001b[39m=\u001b[39;49mestimator,\n\u001b[0;32m    564\u001b[0m     X\u001b[39m=\u001b[39;49mX,\n\u001b[0;32m    565\u001b[0m     y\u001b[39m=\u001b[39;49my,\n\u001b[0;32m    566\u001b[0m     groups\u001b[39m=\u001b[39;49mgroups,\n\u001b[0;32m    567\u001b[0m     scoring\u001b[39m=\u001b[39;49m{\u001b[39m\"\u001b[39;49m\u001b[39mscore\u001b[39;49m\u001b[39m\"\u001b[39;49m: scorer},\n\u001b[0;32m    568\u001b[0m     cv\u001b[39m=\u001b[39;49mcv,\n\u001b[0;32m    569\u001b[0m     n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    570\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[0;32m    571\u001b[0m     fit_params\u001b[39m=\u001b[39;49mfit_params,\n\u001b[0;32m    572\u001b[0m     pre_dispatch\u001b[39m=\u001b[39;49mpre_dispatch,\n\u001b[0;32m    573\u001b[0m     error_score\u001b[39m=\u001b[39;49merror_score,\n\u001b[0;32m    574\u001b[0m )\n\u001b[0;32m    575\u001b[0m \u001b[39mreturn\u001b[39;00m cv_results[\u001b[39m\"\u001b[39m\u001b[39mtest_score\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    209\u001b[0m         )\n\u001b[0;32m    210\u001b[0m     ):\n\u001b[1;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    221\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:328\u001b[0m, in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[0m\n\u001b[0;32m    308\u001b[0m parallel \u001b[39m=\u001b[39m Parallel(n_jobs\u001b[39m=\u001b[39mn_jobs, verbose\u001b[39m=\u001b[39mverbose, pre_dispatch\u001b[39m=\u001b[39mpre_dispatch)\n\u001b[0;32m    309\u001b[0m results \u001b[39m=\u001b[39m parallel(\n\u001b[0;32m    310\u001b[0m     delayed(_fit_and_score)(\n\u001b[0;32m    311\u001b[0m         clone(estimator),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    325\u001b[0m     \u001b[39mfor\u001b[39;00m train, test \u001b[39min\u001b[39;00m indices\n\u001b[0;32m    326\u001b[0m )\n\u001b[1;32m--> 328\u001b[0m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[0;32m    330\u001b[0m \u001b[39m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[0;32m    331\u001b[0m \u001b[39m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[0;32m    332\u001b[0m \u001b[39m# the correct key.\u001b[39;00m\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcallable\u001b[39m(scoring):\n",
      "File \u001b[1;32mc:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m num_failed_fits \u001b[39m==\u001b[39m num_fits:\n\u001b[0;32m    408\u001b[0m     all_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    409\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mAll the \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mIt is very likely that your model is misconfigured.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mYou can try to debug the error by setting error_score=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    412\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    413\u001b[0m     )\n\u001b[1;32m--> 414\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    417\u001b[0m     some_fits_failed_message \u001b[39m=\u001b[39m (\n\u001b[0;32m    418\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mnum_failed_fits\u001b[39m}\u001b[39;00m\u001b[39m fits failed out of a total of \u001b[39m\u001b[39m{\u001b[39;00mnum_fits\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    419\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mThe score on these train-test partitions for these parameters\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBelow are more details about the failures:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mfit_errors_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    424\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 10 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n10 fits failed with the following error:\nTraceback (most recent call last):\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\pipeline.py\", line 416, in fit\n    Xt = self._fit(X, y, **fit_params_steps)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\pipeline.py\", line 370, in _fit\n    X, fitted_transformer = fit_transform_one_cached(\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\joblib\\memory.py\", line 353, in __call__\n    return self.func(*args, **kwargs)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\pipeline.py\", line 950, in _fit_transform_one\n    res = transformer.fit_transform(X, y, **fit_params)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\base.py\", line 918, in fit_transform\n    return self.fit(X, y, **fit_params).transform(X)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n    data_to_wrap = f(self, X, *args, **kwargs)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 240, in transform\n    return self._transform(X, func=self.func, kw_args=self.kw_args)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\", line 312, in _transform\n    return func(X, **(kw_args if kw_args else {}))\n  File \"C:\\Users\\dessa\\AppData\\Local\\Temp\\ipykernel_364\\580279345.py\", line 4, in bag_of_words\n    bag_of_words = binary_representation.fit_transform(texts.tolist)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1383, in fit_transform\n    vocabulary, X = self._count_vocab(raw_documents, self.fixed_vocabulary_)\n  File \"c:\\Users\\dessa\\anaconda3\\envs\\Master\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\", line 1268, in _count_vocab\n    for doc in raw_documents:\nTypeError: 'method' object is not iterable\n"
     ]
    }
   ],
   "source": [
    "# k-fold cross-validation\n",
    "k = 10\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "# Calculate accuracy using cross_val_score\n",
    "accuracy_scores = cross_val_score(complete_pipeline, X, y, cv=skf, scoring='accuracy')\n",
    "\n",
    "# Calculate and print mean accuracy across all folds\n",
    "# mean_accuracy = accuracy_scores.mean()\n",
    "# print(f'Mean Accuracy: {mean_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply initial steps on the whole dataset\n",
    "data_preprocessed = pipeline.named_steps['preprocessor'].transform(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline KNN\n",
    "\n",
    "Article of A. Lamkanfi (Comparing...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_preprocessed = data_preprocess_pipeline.transform(bug_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding\n",
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Create a KNN classifier\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'bug_id', 'description', 'bug_severity', 'binary_severity',\n",
       "       'preprocess_desc'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_preprocessed.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-fold cross-validation\n",
    "k = 10\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "X = data_preprocessed['preprocess_desc']\n",
    "y = data_preprocessed['binary_severity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - ROC AUC: 0.5014\n",
      "Fold 1 - Train Accuracy: 0.7655, Test Accuracy: 0.7580\n",
      "Fold 2 - ROC AUC: 0.4995\n",
      "Fold 2 - Train Accuracy: 0.7649, Test Accuracy: 0.7571\n",
      "Fold 3 - ROC AUC: 0.5056\n",
      "Fold 3 - Train Accuracy: 0.7641, Test Accuracy: 0.7631\n",
      "Fold 4 - ROC AUC: 0.5031\n",
      "Fold 4 - Train Accuracy: 0.7642, Test Accuracy: 0.7614\n",
      "Fold 5 - ROC AUC: 0.4988\n",
      "Fold 5 - Train Accuracy: 0.7648, Test Accuracy: 0.7587\n",
      "Fold 6 - ROC AUC: 0.5001\n",
      "Fold 6 - Train Accuracy: 0.7654, Test Accuracy: 0.7578\n",
      "Fold 7 - ROC AUC: 0.5031\n",
      "Fold 7 - Train Accuracy: 0.7645, Test Accuracy: 0.7605\n",
      "Fold 8 - ROC AUC: 0.5094\n",
      "Fold 8 - Train Accuracy: 0.7643, Test Accuracy: 0.7622\n",
      "Fold 9 - ROC AUC: 0.5050\n",
      "Fold 9 - Train Accuracy: 0.7643, Test Accuracy: 0.7614\n",
      "Fold 10 - ROC AUC: 0.5088\n",
      "Fold 10 - Train Accuracy: 0.7644, Test Accuracy: 0.7614\n",
      "Mean Train Accuracy: 0.7646, Mean Test Accuracy: 0.7602, Mean AUC: 0.5035\n"
     ]
    }
   ],
   "source": [
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "aucs = []\n",
    "\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    # Fit and transform TF-IDF vectors\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    knn_classifier.fit(X_train_tfidf, y_train)\n",
    "    y_pred = knn_classifier.predict(X_test_tfidf)\n",
    "\n",
    "    # Calculate and store test accuracy\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    print(f'Fold {fold + 1} - ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "    # Predict on the training data and calculate train accuracy\n",
    "    y_train_pred = knn_classifier.predict(X_train_tfidf)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    print(f'Fold {fold + 1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "mean_train_accuracy = sum(train_accuracies) / k\n",
    "mean_test_accuracy = sum(test_accuracies) / k\n",
    "mean_aucs = sum(aucs) / k\n",
    "print(f'Mean Train Accuracy: {mean_train_accuracy:.4f}, Mean Test Accuracy: {mean_test_accuracy:.4f}, Mean AUC: {mean_aucs:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline SVM\n",
    "\n",
    "Article of A. Lamkanfi (Comparing...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Create an SVM classifier\n",
    "svm_classifier = SVC(C=100.0, kernel='rbf', gamma=0.001, probability=True) # how set cost=100.0?\n",
    "\n",
    "# k-fold cross-validation\n",
    "k = 10\n",
    "skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n",
    "\n",
    "X = data_preprocessed['preprocess_desc']\n",
    "y = data_preprocessed['binary_severity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - ROC AUC: 0.7914\n",
      "Fold 1 - Train Accuracy: 0.7705, Test Accuracy: 0.7714\n",
      "Fold 2 - ROC AUC: 0.7779\n",
      "Fold 2 - Train Accuracy: 0.7727, Test Accuracy: 0.7625\n",
      "Fold 3 - ROC AUC: 0.7896\n",
      "Fold 3 - Train Accuracy: 0.7706, Test Accuracy: 0.7649\n",
      "Fold 4 - ROC AUC: 0.8102\n",
      "Fold 4 - Train Accuracy: 0.7705, Test Accuracy: 0.7703\n",
      "Fold 5 - ROC AUC: 0.8145\n",
      "Fold 5 - Train Accuracy: 0.7703, Test Accuracy: 0.7658\n",
      "Fold 6 - ROC AUC: 0.8014\n",
      "Fold 6 - Train Accuracy: 0.7715, Test Accuracy: 0.7685\n",
      "Fold 7 - ROC AUC: 0.7894\n",
      "Fold 7 - Train Accuracy: 0.7709, Test Accuracy: 0.7658\n",
      "Fold 8 - ROC AUC: 0.7957\n",
      "Fold 8 - Train Accuracy: 0.7728, Test Accuracy: 0.7631\n",
      "Fold 9 - ROC AUC: 0.7996\n",
      "Fold 9 - Train Accuracy: 0.7727, Test Accuracy: 0.7614\n",
      "Fold 10 - ROC AUC: 0.7802\n",
      "Fold 10 - Train Accuracy: 0.7703, Test Accuracy: 0.7640\n",
      "Mean Train Accuracy: 0.7713, Mean Test Accuracy: 0.7658, Mean AUC: 0.7950\n"
     ]
    }
   ],
   "source": [
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "aucs = []\n",
    "\n",
    "for fold, (train_indices, test_indices) in enumerate(skf.split(X, y)):\n",
    "    X_train, X_test = X.iloc[train_indices], X.iloc[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "\n",
    "    # Fit and transform TF-IDF vectors\n",
    "    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "    X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "    svm_classifier.fit(X_train_tfidf, y_train)\n",
    "    y_pred = svm_classifier.predict(X_test_tfidf)\n",
    "\n",
    "    # Calculate and store test accuracy\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    # Calculate ROC curve and AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, svm_classifier.predict_proba(X_test_tfidf)[:, 1])\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    aucs.append(roc_auc)\n",
    "    print(f'Fold {fold + 1} - ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "    # Predict on the training data and calculate train accuracy\n",
    "    y_train_pred = svm_classifier.predict(X_train_tfidf)\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    print(f'Fold {fold + 1} - Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')\n",
    "\n",
    "mean_train_accuracy = sum(train_accuracies) / k\n",
    "mean_test_accuracy = sum(test_accuracies) / k\n",
    "mean_aucs = sum(aucs) / k\n",
    "print(f'Mean Train Accuracy: {mean_train_accuracy:.4f}, Mean Test Accuracy: {mean_test_accuracy:.4f}, Mean AUC: {mean_aucs:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline for production\n",
    "production_pipeline = Pipeline([\n",
    "    ('bug_severity_filter', FunctionTransformer(filter_bug_severity, kw_args={'col': 'bug_severity'})),\n",
    "    ('binary_feature', FunctionTransformer(create_binary_feature, kw_args={'col': 'bug_severity'})),\n",
    "    ('preprocessing', TextPreprocessor()),\n",
    "    ('embedding', Word2VecEmbedding()),\n",
    "    ('classifier', SVC())\n",
    "])\n",
    "\n",
    "# Fit the production pipeline on the entire dataset\n",
    "production_pipeline.fit(X_text, y)  # Assuming X_text and y are already defined\n",
    "\n",
    "# Make predictions on new, unseen data\n",
    "new_data = ['New sentence 1.', 'New sentence 2.', ...]\n",
    "predictions = production_pipeline.predict(new_data)\n",
    "print(predictions)\n",
    "# In this production pipeline, I've removed the data splitting step and fitted the pipeline on the entire dataset.\n",
    "# Then, I can use this pipeline to make predictions on new, unseen data by calling the predict method with the new data. This is a common approach in production when you're deploying a trained model for making predictions on real-world data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
