{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "os.environ['USER'] = \"rmoine\"\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import *\n",
    "from llama.main import compute_metrics_from_files, DatasetName, compute_metrics_from_list, get_tokenizer\n",
    "import llama.main as m\n",
    "from sklearn.metrics import f1_score, auc, roc_curve\n",
    "from PIL import Image\n",
    "from pandasql import sqldf\n",
    "from io import BytesIO\n",
    "import base64\n",
    "from plotly.graph_objects import Figure\n",
    "import win32clipboard\n",
    "import textwrap\n",
    "import colorsys\n",
    "import optuna\n",
    "import tqdm\n",
    "def img_to_clipboard(fig: Figure):\n",
    "    img_bytes = fig.to_image(format=\"png\")\n",
    "    image = Image.open(BytesIO(img_bytes))\n",
    "    \n",
    "    output = BytesIO()\n",
    "    image.convert('RGB').save(output, 'BMP')\n",
    "    data = output.getvalue()[14:]\n",
    "    output.close()\n",
    "    win32clipboard.OpenClipboard()\n",
    "    win32clipboard.EmptyClipboard()\n",
    "    win32clipboard.SetClipboardData(win32clipboard.CF_DIB, data)\n",
    "    win32clipboard.CloseClipboard()\n",
    "root = Path(f\"../../data/inference/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\robin\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [01:51<00:00,  2.22s/it]\n",
      "c:\\Users\\robin\\Documents\\projets\\severityPrediction\\src\\llm\\llama\\main.py:703: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[pred_field] = data[pred_field].apply(lambda x: -2 if np.isnan(x) else int(x))\n",
      "c:\\Users\\robin\\Documents\\projets\\severityPrediction\\src\\llm\\llama\\main.py:704: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"binary_severity\"] = np.where(\n",
      "c:\\Users\\robin\\Documents\\projets\\severityPrediction\\src\\llm\\llama\\main.py:707: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.rename({\"binary_severity\": \"true\", pred_field: \"pred\"}, axis=1, inplace=True)\n",
      "c:\\Users\\robin\\Documents\\projets\\severityPrediction\\src\\llm\\llama\\main.py:716: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"pred_text\"] = data[\"pred\"].apply(lambda x: mapping_dict[x])\n",
      "c:\\Users\\robin\\Documents\\projets\\severityPrediction\\src\\llm\\llama\\main.py:717: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"true_text\"] = data[\"true\"].apply(lambda x: mapping_dict[x])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>dataset_type</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>folder_data</th>\n",
       "      <th>dataset_choice</th>\n",
       "      <th>model_name</th>\n",
       "      <th>token</th>\n",
       "      <th>n_tokens_infered_max</th>\n",
       "      <th>seed_start</th>\n",
       "      <th>seed_end</th>\n",
       "      <th>n_chunks</th>\n",
       "      <th>interval_idx</th>\n",
       "      <th>id_name</th>\n",
       "      <th>field_input</th>\n",
       "      <th>folder_out</th>\n",
       "      <th>path_data_json</th>\n",
       "      <th>path_data_folder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.515689</td>\n",
       "      <td>eclipse_72k</td>\n",
       "      <td>[[34, 0, 0, 0], [0, 0, 0, 0], [0, 8566, 9430, ...</td>\n",
       "      <td>[1.0, 0.0, 0.3334276218089244, 0.0308030803080...</td>\n",
       "      <td>14.364980</td>\n",
       "      <td>/project/6023391/rmoine/data</td>\n",
       "      <td>eclipse_72k</td>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>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</td>\n",
       "      <td>7364</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>_19497238</td>\n",
       "      <td>description</td>\n",
       "      <td>/project/6023391/rmoine/data/inference__19497238</td>\n",
       "      <td>/project/6023391/rmoine/data/eclipse_72k.json</td>\n",
       "      <td>inference__19497238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.483121</td>\n",
       "      <td>mozilla_200k</td>\n",
       "      <td>[[0, 0, 0], [2803, 10372, 67], [9126, 27655, 2...</td>\n",
       "      <td>[0.0, 0.404610973492754, 0.012435677530017154]</td>\n",
       "      <td>21.100388</td>\n",
       "      <td>/project/6023391/rmoine/data</td>\n",
       "      <td>mozilla_200k</td>\n",
       "      <td>meta-llama/Llama-2-13b-chat-hf</td>\n",
       "      <td>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</td>\n",
       "      <td>7364</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>_19497277</td>\n",
       "      <td>description</td>\n",
       "      <td>/project/6023391/rmoine/data/inference__19497277</td>\n",
       "      <td>/project/6023391/rmoine/data/mozilla_200k.json</td>\n",
       "      <td>inference__19497277</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    roc_auc  dataset_type                                   confusion_matrix  \\\n",
       "0  0.515689   eclipse_72k  [[34, 0, 0, 0], [0, 0, 0, 0], [0, 8566, 9430, ...   \n",
       "1  0.483121  mozilla_200k  [[0, 0, 0], [2803, 10372, 67], [9126, 27655, 2...   \n",
       "\n",
       "                                                  f1   accuracy  \\\n",
       "0  [1.0, 0.0, 0.3334276218089244, 0.0308030803080...  14.364980   \n",
       "1     [0.0, 0.404610973492754, 0.012435677530017154]  21.100388   \n",
       "\n",
       "                    folder_data dataset_choice  \\\n",
       "0  /project/6023391/rmoine/data    eclipse_72k   \n",
       "1  /project/6023391/rmoine/data   mozilla_200k   \n",
       "\n",
       "                       model_name                                  token  \\\n",
       "0  meta-llama/Llama-2-13b-chat-hf  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   \n",
       "1  meta-llama/Llama-2-13b-chat-hf  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   \n",
       "\n",
       "   n_tokens_infered_max seed_start seed_end  n_chunks  interval_idx  \\\n",
       "0                  7364       None     None        10             0   \n",
       "1                  7364       None     None        10             0   \n",
       "\n",
       "     id_name  field_input                                        folder_out  \\\n",
       "0  _19497238  description  /project/6023391/rmoine/data/inference__19497238   \n",
       "1  _19497277  description  /project/6023391/rmoine/data/inference__19497277   \n",
       "\n",
       "                                   path_data_json     path_data_folder  \n",
       "0   /project/6023391/rmoine/data/eclipse_72k.json  inference__19497238  \n",
       "1  /project/6023391/rmoine/data/mozilla_200k.json  inference__19497277  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l = []\n",
    "tokenizer = get_tokenizer(m.default_token, m.default_model)\n",
    "pathes = list(root.rglob(\"inference__*\"))\n",
    "for path_data in tqdm.tqdm(pathes):\n",
    "    with open(path_data / \"parameters.json\") as fp:\n",
    "        parameters = json.load(fp)\n",
    "    dataset_type = parameters[\"dataset_choice\"]\n",
    "    files_data = list(path_data.rglob(f\"predictions_*.json\"))\n",
    "    if len(files_data) == 0:\n",
    "        continue\n",
    "    for f in files_data:\n",
    "        d = []\n",
    "        with open(f) as fp:\n",
    "            for line in fp.readlines():\n",
    "                line = json.loads(line)\n",
    "                n_tokens = len(tokenizer(line['input'])['input_ids'])\n",
    "                l.append({\"n_tokens\":n_tokens,**line,\"dataset_type\":dataset_type,\"parameters\":{**parameters,\"path_data_folder\": path_data.stem}})\n",
    "df_elems = pd.DataFrame(l)\n",
    "l = []\n",
    "for dataset_type in df_elems[\"dataset_type\"].unique():\n",
    "    d = df_elems.query(f\"dataset_type == '{dataset_type}'\").to_dict(orient=\"records\")\n",
    "    confusion_matrix, f1, _ = compute_metrics_from_list(d, pred_field=\"severity_pred\")\n",
    "    accuracy = np.sum(np.diag(confusion_matrix)) / np.sum(confusion_matrix)\n",
    "    df1 = pd.DataFrame(d)\n",
    "    fpr, tpr, thresholds = roc_curve(y_true=np.array(df1['binary_severity']), y_score=np.array(df1['severity_pred']))\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    l.append({\"roc_auc\":roc_auc, \"dataset_type\":dataset_type,\"confusion_matrix\":confusion_matrix,\"f1\":f1,\"accuracy\":accuracy*100, **d[0][\"parameters\"]})\n",
    "df = pd.DataFrame(l)\n",
    "display(df.head())\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_elems.to_json(\"../../data/inference/predictions.json\",orient=\"records\")\n",
    "df.to_json(\"../../data/inference/metrics.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\robin\\Documents\\projets\\severityPrediction\\src\\llm\\llama\\main.py:865: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n",
      "c:\\Users\\robin\\Documents\\projets\\severityPrediction\\src\\llm\\llama\\main.py:865: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    dataset_type = df.iloc[i].dataset_type\n",
    "    data = df.iloc[i]\n",
    "    possibilities_pred = sorted(list(df_elems.query(f\"dataset_type == '{dataset_type}'\")[\"severity_pred\"].unique()))\n",
    "    compute_metrics_from_files(data.confusion_matrix,\n",
    "                            f1=data.f1,\n",
    "                            folder_out=Path(\"../../data/inference/\"),\n",
    "                            data_full=None,\n",
    "                            possibilities_pred=possibilities_pred,\n",
    "                            id=\"_\"+dataset_type\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6285,\n",
       " 6339,\n",
       " 6384,\n",
       " 6388,\n",
       " 6409,\n",
       " 6421,\n",
       " 6500,\n",
       " 6646,\n",
       " 6758,\n",
       " 6872,\n",
       " 6875,\n",
       " 6970,\n",
       " 6978,\n",
       " 7025,\n",
       " 7032,\n",
       " 7045,\n",
       " 7055,\n",
       " 7081,\n",
       " 7134,\n",
       " 7148,\n",
       " 7167,\n",
       " 7172,\n",
       " 7180,\n",
       " 7193,\n",
       " 7206,\n",
       " 7208,\n",
       " 7227,\n",
       " 7233,\n",
       " 7235,\n",
       " 7288,\n",
       " 7301,\n",
       " 7307,\n",
       " 7321,\n",
       " 7340,\n",
       " 7364]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_elems.query(\"severity_pred == -2\")['n_tokens'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6910,\n",
       " 6921,\n",
       " 6923,\n",
       " 6924,\n",
       " 6926,\n",
       " 6950,\n",
       " 6983,\n",
       " 7006,\n",
       " 7021,\n",
       " 7053,\n",
       " 7102,\n",
       " 7108,\n",
       " 7144,\n",
       " 7166,\n",
       " 7189,\n",
       " 7210,\n",
       " 7212,\n",
       " 7221,\n",
       " 7357,\n",
       " 7364]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(df_elems.query(\"severity_pred != -2\")['n_tokens'].unique())[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "severityPrediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
