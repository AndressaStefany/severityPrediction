#!/bin/bash
#SBATCH --nodes=1
#SBATCH --gpus-per-node=v100l:4 # on cedar choose one v100l gpu but can be also p100l
#SBATCH --cpus-per-task=1 # change this parameter to 2,4,6,... and increase "--num_workers" accordingly to see the effect on performance
#SBATCH --time=00:30:00           # duration (JJ-HH:MM:SS)
#SBATCH --output=log-%x-%j.out
#SBATCH --error=log-%x-%j.err
#SBATCH --mail-user=robin.moine456@gmail.com
#SBATCH --mail-type=ALL
#SBATCH --mem=8G

# syntax of
# Capture the start time
start_time=$(date +"%Y-%m-%d %H:%M:%S")

# loading modules
module load python/3.11.5
module load cuda/11.4
virtualenv --no-download $SLURM_TMPDIR/env
source $SLURM_TMPDIR/env/bin/activate
# pip install torch transformers accelerate huggingface_hub xformers pandas scikit-learn nltk bitsandbytes sentencepiece protobuf tqdm shap peft bitsandbytes trl --no-index
pip install --no-index --upgrade pip
pip install numpy==1.24.2 --no-index
pip install matplotlib --no-index

pip install $HOME/slicer-0.0.7-py3-none-any.whl --no-index
pip install $HOME/shap-0.43.0-cp311-cp311-linux_x86_64.whl --no-index

pip install torch --no-index
pip install transformers --no-index
pip install seaborn --no-index
pip install huggingface_hub --no-index
pip install xformers accelerate --no-index
pip install scikit-learn bitsandbytes sentencepiece protobuf tqdm --no-index
# pip install peft --no-index
# pip install trl
# Execution of the script: replace by python path_to_your_script
# Do not forget to change the pathes to absolute pathes (dont hesitate to use $USER variable)
python /project/def-aloise/$USER/main.py


# Capture the end time
end_time=$(date +"%Y-%m-%d %H:%M:%S")

# Calculate and display the execution time
start_seconds=$(date -d "$start_time" '+%s')
end_seconds=$(date -d "$end_time" '+%s')
execution_time=$((end_seconds - start_seconds))

echo "Execution time: $execution_time seconds"