#!/bin/bash
#SBATCH --nodes=1
#SBATCH --gpus-per-node=v100l:1 
#SBATCH --cpus-per-task=1 
#SBATCH --time=03-00:00:00
#SBATCH --output=log-%x-%j.out
#SBATCH --error=log-%x-%j.err
#SBATCH --mail-user=robin.moine456@gmail.com
#SBATCH --mail-type=ALL
#SBATCH --mem=8G

start_time=$$(date +"%Y-%m-%d %H:%M:%S")

module load StdEnv/2020  gcc/9.3.0  cuda/11.4 arrow python/3.10.2 cudnn
virtualenv $$SLURM_TMPDIR/MYENV
source $$SLURM_TMPDIR/MYENV/bin/activate
pip install /home/rmoine/docstring_parser-0.15-py3-none-any.whl --no-index
pip install /home/rmoine/shtab-1.6.4-py3-none-any.whl --no-index
pip install /home/rmoine/tyro-0.5.10-py3-none-any.whl --no-index
pip install /home/rmoine/trl-0.7.2-py3-none-any.whl --no-index
pip install bitsandbytes==0.41.1 --no-index 
pip install transformers torch peft accelerate xformers scikit-learn sentencepiece huggingface_hub protobuf tqdm nltk --no-index
pip install datasets --no-index
pip install seaborn --no-index
pip install matplotlib --no-index
pip install pandas --no-index
pip install h5py --no-index
pip install fire --no-index
pip install optuna --no-index


dataset_choice=$dataset_choice
id_name="_$$SLURM_JOB_ID"
model_name="meta-llama/Llama-2-13b-chat-hf"
n_tokens_infered_max=7364
n_chunks=$n_chunks
interval_idx=$interval_idx
missing_file=$missing_file

cd /project/def-aloise/$$USER/

python /project/def-aloise/$$USER/main.py main_inference \
        --dataset_choice=$$dataset_choice \
        --id_name=$$id_name \
        --model_name=$$model_name \
        --n_tokens_infered_max=$$n_tokens_infered_max \
        --n_chunks=$$n_chunks \
        --interval_idx=$$interval_idx \
        --missing_file=$$missing_file

# Capture the end time
end_time=$$(date +"%Y-%m-%d %H:%M:%S")
# Calculate and display the execution time
start_seconds=$$(date -d "$$start_time" '+%s')
end_seconds=$$(date -d "$$end_time" '+%s')
execution_time=$$((end_seconds - start_seconds))
echo "Execution time: $$execution_time seconds"