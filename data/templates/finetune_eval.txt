#!/bin/bash
#SBATCH --nodes=1
#SBATCH --gpus-per-node=a100:1 
#SBATCH --cpus-per-task=1 
#SBATCH --time=00-23:59:00
#SBATCH --output=log-%x-%j.out
#SBATCH --error=log-%x-%j.err
#SBATCH --mail-user=robinandressa0@gmail.com
#SBATCH --mail-type=ALL
#SBATCH --mem=8G

start_time=$$(date +"%Y-%m-%d %H:%M:%S")
export TORCH_CUDNN_V8_API_DISABLED=1
module load StdEnv/2020  gcc/9.3.0  cuda/11.4 arrow python/3.10.2 cudnn
virtualenv $$SLURM_TMPDIR/MYENV
source $$SLURM_TMPDIR/MYENV/bin/activate

pip install -r requirements.txt --no-index

dataset_choice=$dataset_choice
lora_r=$lora_r
id_name="_$$SLURM_JOB_ID_redo"
lora_alpha=$lora_alpha
lora_dropout=$lora_dropout
model_name=$model_name
learning_rate=$learning_rate
limit_tokens=500
tr_bs=4
num_train_epochs=2
tr_weighted_sampling=$tr_weighted_sampling
prompt_id=$prompt_id
resume_from_checkpoint=$resume_from_checkpoint
cd /project/def-aloise/$$USER/

python /project/def-aloise/$$USER/main.py qlora_classification \
        --dataset_choice=$$dataset_choice \
        --id=$$id_name \
        --lora_alpha=$$lora_alpha \
        --lora_r=$$lora_r \
        --lora_dropout=$$lora_dropout \
        --model_name=$$model_name \
        --limit_tokens=$$limit_tokens \
        --num_train_epochs=$$num_train_epochs \
        --learning_rate=$$learning_rate \
        --tr_bs=$$tr_bs \
        --tr_weighted_sampling=$$tr_weighted_sampling \
        --prompt_id=$$prompt_id \
        --resume_from_checkpoint=$$resume_from_checkpoint


# Capture the end time
end_time=$$(date +"%Y-%m-%d %H:%M:%S")

# Calculate and display the execution time
start_seconds=$$(date -d "$$start_time" '+%s')
end_seconds=$$(date -d "$$end_time" '+%s')
execution_time=$$((end_seconds - start_seconds))

echo "Execution time: $$execution_time seconds"